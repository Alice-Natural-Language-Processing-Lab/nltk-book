{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Python Coding Style"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nuse four spaces per indentation level.\\navoid tabs for indentation\\nLines should be less than 80 characters long\\n'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "use four spaces per indentation level.\n",
    "avoid tabs for indentation\n",
    "Lines should be less than 80 characters long\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Procedural vs Declarative Style"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import nltk\n",
    "tokens = nltk.corpus.brown.words(categories='news')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4.40 --- 0.5021 seconds ---\n"
     ]
    }
   ],
   "source": [
    "''' procedural style\n",
    "as the machine does\n",
    "like cpu registers '''\n",
    "import time\n",
    "start_time = time.time()\n",
    "count = 0\n",
    "total = 0\n",
    "for token in tokens:\n",
    "    count += 1\n",
    "    total += len(token)\n",
    "avg = total / count\n",
    "print(\"%.2f --- %.4f seconds ---\" % ( avg, (time.time() - start_time)) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4.40 --- 0.4704 seconds ---\n"
     ]
    }
   ],
   "source": [
    "''' declarative\n",
    "Implementation details are left to the Python interpreter '''\n",
    "start_time = time.time()\n",
    "total = sum(len(t) for t in tokens)\n",
    "avg = total / len(tokens)\n",
    "print(\"%.2f --- %.4f seconds ---\" % ( avg, (time.time() - start_time)) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "start_time = time.time()\n",
    "word_list = []\n",
    "i = 0\n",
    "while i < len(tokens):\n",
    "    j = 0\n",
    "    while j < len(word_list) and word_list[j] <= tokens[i]:\n",
    "        j += 1\n",
    "    if j == 0 or tokens[i] != word_list[j-1]:\n",
    "        word_list.insert(j, tokens[i])\n",
    "    i += 1\n",
    "print(\"--- %.4f seconds ---\" % (time.time() - start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- 0.4685 seconds ---\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "word_list = sorted(set(tokens))\n",
    "print(\"--- %.4f seconds ---\" % (time.time() - start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  1   5.40% the\n",
      "  2  10.42% ,\n",
      "  3  14.67% .\n",
      "  4  17.78% of\n",
      "  5  20.19% and\n",
      "  6  22.40% to\n",
      "  7  24.29% a\n",
      "  8  25.97% in\n"
     ]
    }
   ],
   "source": [
    "fd = nltk.FreqDist(nltk.corpus.brown.words())\n",
    "cumulative = 0.0\n",
    "most_common_words = [word for (word, count) in fd.most_common()]\n",
    "''' enunmerate to produce duple ( index, (word,freq )\n",
    "index + 1 used as numeration for ranking '''\n",
    "for rank, word in enumerate(most_common_words):\n",
    "    cumulative += fd.freq(word)\n",
    "    print(\"%3d %6.2f%% %s\" % (rank + 1, cumulative * 100, word))\n",
    "    if cumulative > 0.25:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "text = nltk.corpus.gutenberg.words('milton-paradise.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "unextinguishable --- 0.2505 seconds ---\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "longest = ''\n",
    "''' it's temping to use a variable to store max or min '''\n",
    "for word in text:\n",
    "    if len(word) > len(longest):\n",
    "        longest = word\n",
    "print(\"%s --- %.4f seconds ---\" % (longest, (time.time() - start_time)) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- 0.4259 seconds ---\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "maxlen = max(len(word) for word in text)\n",
    "[word for word in text if len(word) == maxlen]\n",
    "print(\"--- %.4f seconds ---\" % ( (time.time() - start_time)) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
